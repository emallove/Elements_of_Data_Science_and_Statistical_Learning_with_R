---
title: "CSCI E-63C Week 10 Problem Set"
author: "Ethan Mallove"
date: "Nov 7, 2019"
output:
  html_document:
    toc: true
---

```{r setup, include=FALSE}
library(MASS)
library(class)
library(ggplot2)
library(e1071)

# Incurs a compiler error
# library("kknn")
knitr::opts_chunk$set(echo = TRUE)
```

# Preface

> For this week problem set we will use WiFi localization data (the one we worked with on week 2) to fit logistic regression model and evaluate performance of LDA, QDA and KNN classifiers.  As we have seen earlier this dataset should allow to locate phones fairly well by relying on the strength of WiFi signal, so we should expect to see fairly low error rates for our classifiers.  Let's see whether some of those classifiers perform better than others on this data.
> 
> **Important note:** *For the purposes of all problems in this week problem set, we will be predicting whether the phone is at location=3 or not, as opposed to working with multi-class predictor.  In other words, before you proceed with any of the problems in this assignment, please convert the four-levels outcome to the outcome with only two levels: location=3 (must be 500 of those) and not (must be 1500 of them).*
> 
> *If you are creating a new column containing this binary outcome, please make sure that the original outcome with four columns is NOT used inadvertently as one of the predictors.  If you are getting invariably 100% accuracy regardless of the choice of the method or split of the data into training and test, chances are your code is using original four-levels outcome as a predictor.*

```{r wifiData}
library(MASS)
# An extra boolean column has been added to mark location=3 true or false (0, 1)
wifiData = matrix(scan("wifi_localization.txt"), ncol = 9, byrow = TRUE)

# Plot to pdf, so we can zoom in SVG
pdf("wifidata-pairs.pdf")
pairs(wifiData)

# Go back to default graphics device
dev.off()
```

# Problem 1 (10 points): logistic regression

> Fit logistic regression model of the binary categorical outcome (location=3 or not) using seven WiFi signals strengths as predictors in the model.  Produce summary of the model, describe which attributes appear to be significantly associated with the categorical outcome in this model.  Use this model to make predictions on the entire dataset and compare these predictions and corresponding true values of the class attribute using confusion matrix (i.e. contingency table).  Calculate error rate (would this be training or test error in this case?), sensitivity and specificity (assuming that we are predicting class "location=3").  Describe the results.


```{r}
glmFit <- glm(V9~.,data=as.data.frame(wifiData),family=binomial)
summary(glmFit)
# p<0.05 in randomized data:
# pTmp <- NULL
# for ( iSim in 1:1000 ) {
#   wTmp <- wifiData
#   wTmp[,9] <- sample(wTmp[,9])
#   glmSim <- glm(V9~.,data=as.data.frame(wTmp),family=binomial)
#   pTmp <- rbind(pTmp,summary(glmSim)$coefficients[-1,"Pr(>|z|)"])
# }
# dim(pTmp)
# sum(pTmp<0.05)/prod(dim(pTmp))
# sum(apply(pTmp,1,min)<0.05)/nrow(pTmp)
# sum(pTmp<0.03)/prod(dim(pTmp))
# sum(apply(pTmp,1,min)<0.03)/nrow(pTmp)
```

```{r 2}
boxplot(predict(glmFit,type="response")~wifiData[,9])
quantile(predict(glmFit,type="response"))
table(wifiData[,9],c("loc 3","loc not 3")[1+(predict(glmFit)>0.0)])
tblTmp <- table(wifiData[,9],c("loc 3","loc not 3")[1+(predict(glmFit,type="response")>0.5)])
tblTmp
# sensitivity for predicting "loc 3":
tblTmp[2,2] / sum(tblTmp[2,])
# specificity for predicting "loc not 3":
tblTmp[1,1] / sum(tblTmp[1,])
rocDatTmp <- NULL

for ( qTmp in quantile(predict(glmFit,type="response"),(0:10)/10) ) {
  tblTmp <- table(wifiData[,9], factor(c("loc 3", "loc not 3")[1+(predict(glmFit, type="response")>=qTmp)], c("loc 3", "loc not 3")))
  cat(qTmp,tblTmp[2,2] / sum(tblTmp[2,]),tblTmp[1,1] / sum(tblTmp[1,]),fill=TRUE)
  rocDatTmp <- rbind(rocDatTmp,c(1-tblTmp[1,1] / sum(tblTmp[1,]),tblTmp[2,2] / sum(tblTmp[2,])))
}
plot(rocDatTmp,ylab="Sensitivity",xlab="1-Specificity")
abline(0,1,lty=2)
```


Sensitivity: 0.522
Specificity: 0.913333

# Problem 2 (10 points): LDA and QDA

> Using LDA and QDA implementations available in the package `MASS`, fit LDA and QDA classifiers on the entire dataset and calculate confusion matrix, (training) error rate, sensitivity and specificity for each of them.  Compare them to those of logistic regression.  Describe the results.

```{r wifiLDA}
wifiLDA <- lda(V9~.,data=as.data.frame(wifiData))
plot(wifiLDA)
tblTmp <- table(wifiData[,9], predict(wifiLDA, newdata=as.data.frame(wifiData))$class)
tblTmp[2,2] / sum(tblTmp[2,])
tblTmp[1,1] / sum(tblTmp[1,])
```

Confusion matrix:

```{r wifiLDA__ConfusionMatrix}
table(wifiData[,9], c(0,1)[1 + (predict(wifiLDA, newdata=as.data.frame(wifiData), type="response")$x > quantile(predict(wifiLDA, type="response")$x, 0.85))])
```

Sensitivity: 0.512
Specificity: 0.9213333

```{r wifiQDA}
library(MASS)
# debug(qda)
wifiDataFrame <- as.data.frame(wifiData)
colnames(wifiDataFrame) = c("V1","V2","V3","V4","V5","V6","V7","V8","V9")
wifiQDA <- qda(V9~., data=wifiDataFrame[,-8])
# plot(wifiQDA)
tblTmp <- table(wifiData[,9], predict(wifiQDA, newdata=as.data.frame(wifiData))$class)
tblTmp[2,2] / sum(tblTmp[2,])
tblTmp[1,1] / sum(tblTmp[1,])
```

Big improvement in sensitivity (from LDA and logistic regression)

Sensitivity: 0.882
Specificity: 0.9926667

# Problem 3 (10 points): KNN

> Using `knn` from library `class`, fit KNN classifiers for the entire dataset and calculate confusion matrix, (training) error rate, sensitivity/specificity for  $k=1$, $5$ and $25$ nearest neighbors models.  Compare them to the corresponding results from LDA, QDA and logistic regression. Describe results of this comparison and discuss whether it is surprising to see low *training* error for KNN classifier with $k=1$.

```{r,fig.width=12,fig.height=6}
##?knn
trainIds = sample(1:nrow(wifiData), 1000);
testIds = sample(1:nrow(wifiData), 1000);
wifiKNN <- knn(train = as.matrix(wifiData[trainIds,]), test = as.matrix(wifiData[testIds,]), cl = as.matrix(wifiData[trainIds,9]), k = 1)
tblTmp <- table(wifiData[testIds,9], wifiKNN)
tblTmp
tblTmp[2,2] / sum(tblTmp[2,])
tblTmp[1,1] / sum(tblTmp[1,])
# KNN on all useable attributes:
wifiDataScaled <- wifiData
wifiDataScaled <- scale(wifiDataScaled)

rocDatTmp <- NULL
for ( kTmp in c(1, 5, 25) ) {
  #knnTmp <- knn(train = as.matrix(wifiData[,1:7]), test = as.matrix(wifiData[,1:7]), cl = wifiData[,9], k=kTmp)
  knnTmp <- knn(train = as.matrix(wifiData[trainIds,]), test = as.matrix(wifiData[testIds,]), cl = as.matrix(wifiData[trainIds,9]), k = kTmp)
  tblTmp <- table(wifiData[testIds,9], knnTmp)
  print(paste0("K = ", kTmp))
  print(tblTmp)
  rocDatTmp <- rbind(rocDatTmp, c(kTmp, 1-tblTmp[1,1] / sum(tblTmp[1, ]), tblTmp[2, 2] / sum(tblTmp[2, ])))
}
old.par <- par(mfrow=c(1,2))
plot(rocDatTmp[,-1],xlab="1-Specificity",ylab="Sensitivity")
abline(0,1,lty=2)
plot(rocDatTmp[,1],1-rocDatTmp[,2],xlab="K",ylab="",ylim=c(0,1))
points(rocDatTmp[,1],rocDatTmp[,3],col=2)
legend("topleft",c("Specificity","Sensitivity"),col=1:2,pch=1,text.col=1:2)
par(old.par)
```

Sensitivity: 0.9924528
Specificity: 0.9918367

<!-- Confusion matrix: -->

```{r wifiKNN__ConfusionMatrix}
# table(wifiData[,9], c(0,1)[1 + (predict(wifiKNN, newdata=as.data.frame(wifiData), type="response")$x > quantile(predict(wifiKNN, type="response")$x, 0.85))])
```

# Problem 4 (30 points): compare test errors of logistic regression, LDA, QDA and KNN

> Using resampling approach of your choice (e.g. cross-validation, bootstrap, etc.) obtain test error as well as sensitivity and specificity for each of these methods (logistic regression, LDA, QDA, KNN with $k=1,7,55,351$).  Present results in the form of boxplots, compare test error/sensitivity/specificity across these methods and discuss their relative performance.

```{r compareGlm_Lda_Qda_and_KNN}

iTries = 10
# myDf = data.frame(iTries, c("GLM", "LDA", "QDA"))

myColnames = c("#", "GLM", "LDA", "QDA")

kVals = c(1,7,55,351)
myMatrix = matrix(nrow=iTries, ncol = length(myColnames) + length(kVals))

for ( iTry in 1:iTries ) {
  
  # Generate training and test samples
  trainIdx <- sample(nrow(wifiData),nrow(wifiData),replace=TRUE)
  wTrain <- wifiData[trainIdx,]
  wTrainFrame <- as.data.frame(wTrain)
  wTest <- wifiData[-trainIdx,]
  
  # Model
  glmTry <- glm(V9~.,data=as.data.frame(wTrain),family=binomial)
  ldaTry <- lda(V9~.,data=as.data.frame(wTrain))
  colnames(wTrainFrame) = c("V1","V2","V3","V4","V5","V6","V7","V8","V9")
  colnames(wTest)       = c("V1","V2","V3","V4","V5","V6","V7","V8","V9")
  qdaTry <- qda(V9~.,data=wTrainFrame[,-8])
  # nbTry <- naiveBayes(V9~.,data=as.data.frame(wTrain))
  # nbTry <- naiveBayes(V9~.,data=wTrainFrame[,-8])
 
  # FIXME: 
  #   * use kVals = c(1,7,55,351), instead of hard-coding
  #   * fix packages.install(kknn) compiler error
  # kknnTry1 <- kknn(V9~.,data=wTrainFrame[,-8], k = 1)
  # kknnTry7 <- kknn(V9~.,data=wTrainFrame[,-8], k = 7)
  # kknnTry55 <- kknn(V9~.,data=wTrainFrame[,-8], k = 55)
  # kknnTry351 <- kknn(V9~.,data=wTrainFrame[,-8], k = 351)
  
  # Predict
  glmTestRes     <- as.numeric(predict(glmTry,newdata=as.data.frame(wTest),type="response")>0.5)
  ldaTestRes     <- predict(ldaTry,newdata=as.data.frame(wTest))$class
  qdaTestRes     <- predict(qdaTry,newdata=as.data.frame(wTest))$class
  # nbTestRes      <- predict(nbTry,newdata=as.data.frame(wTest))$class
  # kknnTestRes1   <- predict(kknnTry1,newdata=as.data.frame(wTest))$class
  # kknnTestRes7   <- predict(kknnTry7,newdata=as.data.frame(wTest))$class
  # kknnTestRes55  <- predict(kknnTry55,newdata=as.data.frame(wTest))$class
  # kknnTestRes351 <- predict(kknnTry351,newdata=as.data.frame(wTest))$class
 
  # Tabulate
  tblTstglm     <- table(wTest[,9],glmTestRes)
  tblTstLDA     <- table(wTest[,9],ldaTestRes)
  tblTstQDA     <- table(wTest[,9],qdaTestRes)
  # tblTstNb      <- table(wTest[,9],nbTestRes)
  # tblTstKknn1   <- table(wTest[,9],kknnTestRes1)
  # tblTstKknn7   <- table(wTest[,9],kknnTestRes7)
  # tblTstKknn55  <- table(wTest[,9],kknnTestRes55)
  # tblTstKknn351 <- table(wTest[,9],kknnTestRes351)
 
  # GLM, LDA, and QDA
  myRow = c( iTry,
             1 - (sum(diag(tblTstglm))     / sum(tblTstglm)),
             1 - (sum(diag(tblTstLDA))     / sum(tblTstLDA)),
             1 - (sum(diag(tblTstQDA))     / sum(tblTstQDA))
             # 1 - (sum(diag(tblTstNb))      / sum(tblTstNb))
             # 1 - (sum(diag(tblTstKknn1))   / sum(tblTstKknn1)),
             # 1 - (sum(diag(tblTstKknn7))   / sum(tblTstKknn7)),
             # 1 - (sum(diag(tblTstKknn55))  / sum(tblTstKknn55)),
             # 1 - (sum(diag(tblTstKknn351)) / sum(tblTstKknn351)),
  );
 
  # KNN is special
  for ( kTmp in kVals ) {
    knnTestRes <- knn(train = as.matrix(wTrain), test = as.matrix(wTest), cl = as.matrix(wTrain[,9]), k = kTmp)
    tblTstKnn <- table(wTest[,9], knnTestRes)
    myRow <- append(myRow, c( 1 - (sum(diag(tblTstKnn)) / sum(tblTstKnn) )))
  }

  myMatrix[iTry,] = myRow
}

colnames(myMatrix) <- c(myColnames, sapply(kVals, function(x) { paste("KNN k=",x); } ))
#rownames(myMatrix) <- c(1:iTries)
#rownames(myMatrix) <- c(1,2,3,4,5,6,7,8,9,10)
rownames(myMatrix) <- 1:iTries;

# library(knitr)
print("Test error rates:\n")

boxplot(log(myMatrix[,-1]), las=2, col=rainbow(6, s=0.5), main="Test Error of Classifiers")

myMatrix

# Throws knit error
# %>%
#   kable() %>%
#   kable_styling()

# myDf <- as.data.frame(myMatrix)
# colnames(myDf) <- colnames(c("#", "GLM", "LDA", "QDA"))
# rownames(myDf) <- rownames(1:iTries)
# kable(myDf)
```

KNN outperforms them all - with $k=1$ being the optimal $k$ value.

Interesting to note the degredation in KNN's test error rate as $k$ becomes too large.

# Extra 5 points problem: naive Bayes classifier

> Fit naive Bayes classifier (see lecture slides for examples of using `naiveBayes` function from package `e1071`) to the WiFi localization dataset with binary (location=3 or not) outcome and assess its performance on test data by resampling along with logistic regression, LDA, QDA and KNN in the Problem 4 above.


```{r naiveBayes}

# FIXME

# nb.fit=naiveBayes(Y~X,data=data.frame(Y=y1,X=x1))
# colnames(wTrainFrame) = c("V1","V2","V3","V4","V5","V6","V7","V8","V9")
# nb.fit=naiveBayes(V9~.,data=wTrainFrame[,-8])

# nbTestRes <- predict(nb.fit, newdata=wTest[,9])
# tblTstNb <- table(wTest[,9], nbTestRes)

# predict(nb.fit,newdata=wTest[,9],type="raw")
# 
# plot ( x1, ifelse ( y1 == "A", 0, 1 ), col = ifelse ( y1 ==  "A",  "lightblue",  "orange" ), pch = 19 ) 
# # theoretical probability of B, TRUTH ( dashed ) : 
# points ( xx, exp (-((xx - 2)^2) / 2 ) * 0.75 / ( exp(-((xx - 2)^2) / 2) * 0.75 + exp ( (-xx^2) / 2 ) * 0.25 ), type =  'l', col = 'red', lwd = 2, lty = 2 ) 
# 
# # predicted prob.
# points ( xx, predict ( nb.fit, newdata = data.frame ( X = xx ), type = "raw" )[,2], col = 'red', type =  'l')

```

# Extra 10 points problem: interaction terms in logistic regression

> Add pairwise interaction terms to the logistic regression model fit in the Problem 1 above and evaluate impact of their addition on training **and** test error.  You can add all pairwise interaction terms or a subset of them, in which case the rationale behind selecting such a subset has to be described in your solution.

```{r interactionTerms}
# glmFit <- glm(V9~.,data=as.data.frame(wifiData),family=binomial)

# Add all pair-wise interaction terms
glmFit <- glm(V9 ~ V1 + V1:V2 + V1:V3 + V1:V4 + V1:V5 + V1:V7 + V2:V5 + V2:V7 + V3:V4 + V3:V5 + V3:V7 + V5:V6,data=as.data.frame(wifiData),family=binomial)
summary(glmFit)

boxplot(predict(glmFit,type="response")~wifiData[,9])
quantile(predict(glmFit,type="response"))
table(wifiData[,9],c("loc 3","loc not 3")[1+(predict(glmFit)>0.0)])
tblTmp <- table(wifiData[,9],c("loc 3","loc not 3")[1+(predict(glmFit,type="response")>0.5)])
# tblTmp
# sensitivity for predicting "loc 3":
tblTmp[2,2] / sum(tblTmp[2,])
# specificity for predicting "loc not 3":
tblTmp[1,1] / sum(tblTmp[1,])
rocDatTmp <- NULL

for ( qTmp in quantile(predict(glmFit,type="response"),(0:10)/10) ) {
  tblTmp <- table(wifiData[,9], factor(c("loc 3", "loc not 3")[1+(predict(glmFit, type="response")>=qTmp)], c("loc 3", "loc not 3")))
  cat(qTmp,tblTmp[2,2] / sum(tblTmp[2,]),tblTmp[1,1] / sum(tblTmp[1,]),fill=TRUE)
  rocDatTmp <- rbind(rocDatTmp,c(1-tblTmp[1,1] / sum(tblTmp[1,]),tblTmp[2,2] / sum(tblTmp[2,])))
}
plot(rocDatTmp,ylab="Sensitivity",xlab="1-Specificity")
abline(0,1,lty=2)
```

In the above model, I've added the most significant predictor combinations.  I gathered pairs of terms by first inspecting performance of *all* term pairs ($(V1:V7)^2$).  

```
Show in New WindowClear OutputExpand/Collapse Output
glm.fit: fitted probabilities numerically 0 or 1 occurred
Call:
glm(formula = V9 ~ (V1 + V2 + V3 + V4 + V5 + V6 + V7)^2, family = binomial, 
    data = as.data.frame(wifiData))

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.9222  -0.0010   0.0000   0.0001   4.0874  

Coefficients:
              Estimate Std. Error z value Pr(>|z|)    
(Intercept) -4.380e+02  2.292e+02  -1.911 0.056002 .  
V1          -9.549e+00  2.857e+00  -3.342 0.000832 ***
V2           1.234e+00  2.560e+00   0.482 0.629874    
V3          -3.472e+00  2.629e+00  -1.321 0.186661    
V4          -2.136e+00  2.133e+00  -1.002 0.316583    
V5           7.870e-01  1.494e+00   0.527 0.598459    
V6          -1.571e+00  2.151e+00  -0.730 0.465141    
V7          -1.109e+00  1.869e+00  -0.593 0.552998    
V1:V2        7.017e-02  2.813e-02   2.494 0.012614 *  
V1:V3       -6.972e-02  2.580e-02  -2.702 0.006893 ** 
V1:V4       -1.462e-01  1.915e-02  -7.632 2.31e-14 ***
V1:V5        6.670e-02  1.701e-02   3.922 8.80e-05 ***
V1:V6       -2.136e-02  1.843e-02  -1.159 0.246461    
V1:V7       -5.817e-02  2.413e-02  -2.411 0.015904 *  
V2:V3        9.890e-03  2.312e-02   0.428 0.668849    
V2:V4        2.221e-02  1.907e-02   1.164 0.244304    
V2:V5        2.247e-02  1.317e-02   1.706 0.088034 .  
V2:V6       -2.372e-02  2.335e-02  -1.016 0.309677    
V2:V7       -4.348e-02  2.093e-02  -2.077 0.037800 *  
V3:V4        4.100e-02  1.852e-02   2.214 0.026797 *  
V3:V5       -8.190e-02  1.732e-02  -4.730 2.25e-06 ***
V3:V6       -3.574e-02  2.820e-02  -1.268 0.204973    
V3:V7        6.401e-02  2.398e-02   2.669 0.007605 ** 
V4:V5       -1.048e-02  1.258e-02  -0.833 0.404761    
V4:V6        9.937e-03  1.586e-02   0.627 0.530818    
V4:V7        2.059e-02  1.947e-02   1.058 0.290211    
V5:V6        2.687e-02  1.421e-02   1.891 0.058659 .  
V5:V7       -1.383e-02  1.395e-02  -0.991 0.321446    
V6:V7        9.536e-03  1.667e-02   0.572 0.567338    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 2249.34  on 1999  degrees of freedom
Residual deviance:  143.69  on 1971  degrees of freedom
AIC: 201.69

Number of Fisher Scoring iterations: 12

          0%          25%          50%          75%         100% 
2.220446e-16 1.926224e-12 4.868185e-07 5.843425e-01 9.999999e-01 
   
    loc 3 loc not 3
  0  1486        14
  1    10       490
   
    loc 3 loc not 3
  0  1486        14
  1    10       490
[1] 0.98
[1] 0.9906667
````

In the above output, we use the following formula (`V1 + V1:V2 + V1:V3 + V1:V4 + V1:V5 + V1:V7 + V2:V5 + V2:V7 + V3:V4 + V3:V5 + V3:V7 + V5:V6`) since these pairs are marked significant (`***`, `**`, `*`, or `,`).  This gives our GLM classifier a major boost in predictive power (sensitivity and specificity increase dramatically).