rsTrain <- regsubsets(AG2~.,algaeAG2[bTrain,],nvmax=15,method=jSelect)
# Add up variable selections:
whichSum[,,jSelect] <- whichSum[,,jSelect] + summary(rsTrain)$which
# Calculate test error for each set of variables
# using predict.regsubsets implemented above:
for ( kVarSet in 1:15 ) {
# make predictions:
testPred <- predict(rsTrain,algaeAG2[!bTrain,],id=kVarSet)
# calculate MSE:
mseTest <- mean((testPred-algaeAG2[!bTrain,"AG2"])^2)
# add to data.frame for future plotting:
dfTmp <- rbind(dfTmp,data.frame(sim=iTry,sel=jSelect,vars=kVarSet,
mse=c(mseTest,summary(rsTrain)$rss[kVarSet]/sum(bTrain)),trainTest=c("test","train")))
}
}
}
# plot MSEs by training/test, number of
# variables and selection method:
ggplot(dfTmp,aes(x=factor(vars),y=mse,colour=sel)) + geom_boxplot()+facet_wrap(~trainTest)+theme_bw()
old.par <- par(mfrow=c(2,2),ps=16,mar=c(5,7,2,1))
for ( myMthd in dimnames(whichSum)[[3]] ) {
tmpWhich <- whichSum[,,myMthd] / nTries
image(1:nrow(tmpWhich),1:ncol(tmpWhich),tmpWhich,
xlab="N(vars)",ylab="",xaxt="n",yaxt="n",main=myMthd,
breaks=c(-0.1,0.1,0.25,0.5,0.75,0.9,1.1),
col=c("white","gray90","gray75","gray50","gray25","gray10"))
axis(1,1:nrow(tmpWhich),rownames(tmpWhich))
axis(2,1:ncol(tmpWhich),colnames(tmpWhich),las=2)
}
par(old.par)
# -1 to get rid of intercept that glmnet knows to include:
x <- model.matrix(AG2~.,algaeAG2)[,-1]
head(algaeAG2)
# notice how it created dummy variables for categorical attributes
head(x)
y <- algaeAG2[,"AG2"]
ridgeRes <- glmnet(x,y,alpha=0)
plot(ridgeRes)
cvRidgeRes <- cv.glmnet(x,y,alpha=0)
plot(cvRidgeRes)
cvRidgeRes$lambda.min
cvRidgeRes$lambda.1se
predict(ridgeRes,type="coefficients",s=cvRidgeRes$lambda.min)
predict(ridgeRes,type="coefficients",s=cvRidgeRes$lambda.1se)
# and with lambda's other than default:
cvRidgeRes <- cv.glmnet(x,y,alpha=0,lambda=10^((-80:80)/20))
plot(cvRidgeRes)
ridgeResScaled <- glmnet(scale(x),y,alpha=0)
plot(ridgeResScaled)
cvRidgeResScaled <- cv.glmnet(scale(x),y,alpha=0)
plot(cvRidgeResScaled)
predict(ridgeResScaled,type="coefficients",s=cvRidgeResScaled$lambda.1se)
lassoRes <- glmnet(x,y,alpha=1)
plot(lassoRes)
cvLassoRes <- cv.glmnet(x,y,alpha=1)
plot(cvLassoRes)
# With other than default levels of lambda:
cvLassoRes <- cv.glmnet(x,y,alpha=1,lambda=10^((-120:0)/20))
plot(cvLassoRes)
predict(lassoRes,type="coefficients",s=cvLassoRes$lambda.1se)
predict(lassoRes,type="coefficients",s=cvLassoRes$lambda.min)
lassoResScaled <- glmnet(scale(x),y,alpha=1)
plot(lassoResScaled)
cvLassoResScaled <- cv.glmnet(scale(x),y,alpha=1)
plot(cvLassoResScaled)
predict(lassoResScaled,type="coefficients",s=cvLassoResScaled$lambda.1se)
lassoCoefCnt <- 0
lassoMSE <- NULL
for ( iTry in 1:30 ) {
bTrain <- sample(rep(c(TRUE,FALSE),length.out=nrow(x)))
cvLassoTrain <- cv.glmnet(x[bTrain,],y[bTrain],alpha=1)
lassoTrain <- glmnet(x[bTrain,],y[bTrain],alpha=1)
lassoTrainCoef <- predict(lassoTrain,type="coefficients",s=cvLassoTrain$lambda.1se)
lassoCoefCnt <- lassoCoefCnt + (lassoTrainCoef[-1,1]!=0)
lassoTestPred <- predict(lassoTrain,newx=x[!bTrain,],s=cvLassoTrain$lambda.1se)
lassoMSE <- c(lassoMSE,mean((lassoTestPred-y[!bTrain])^2))
}
mean(lassoMSE)
lassoCoefCnt
fundRaisingData <- read.table("fund-raising-with-predictions.csv", sep=",", header=TRUE)
# DON'T SKIP log-transform selected attributes:
# fundRaisingData[,1:8] <- log(fundRaisingData[,1:8])
# frd <- fundRaisingData
# fundRaisingData <- do.call(data.frame, lapply(frd, function(x) replace(x, is.infinite(x),NA)))
# FIXME: Doesn't work on Mac OS
# resize.win <- function(Width=6, Height=6) {
#         # works for windows
#     dev.off(); # dev.new(width=6, height=6)
#     windows(record=TRUE, width=Width, height=Height)
# }
# resize.win(1000,1000);
# pdf(file = "Rplot.pdf")
# pairs(fundRaisingData)
# dev.off()
summaryMetrics <- NULL
whichAll <- list()
for ( myMthd in c("exhaustive", "backward", "forward", "seqrep") ) {
# 15 because three categorical attributes are represented by dummy variables:
rsRes <- regsubsets(contrib~., fundRaisingData[, 1:12], method=myMthd, nvmax=12)
summRes <- summary(rsRes)
whichAll[[myMthd]] <- summRes$which
for ( metricName in c("rsq", "rss", "adjr2", "cp", "bic") ) {
summaryMetrics <- rbind(summaryMetrics,
data.frame(method=myMthd, metric=metricName,
nvars=1:length(summRes[[metricName]]),
value=summRes[[metricName]]))
}
}
ggplot(summaryMetrics, aes(x=nvars, y=value, shape=method, colour=method)) + geom_path() + geom_point() + facet_wrap(~metric, scales="free") +   theme(legend.position="top")+theme_bw()
old.par <- par(mfrow=c(2, 2), ps=16, mar=c(5, 7, 2, 1))
for ( myMthd in names(whichAll) ) {
image(1:nrow(whichAll[[myMthd]]),
1:ncol(whichAll[[myMthd]]),
whichAll[[myMthd]], xlab="N(vars)", ylab="",
xaxt="n", yaxt="n", breaks=c(-0.5, 0.5, 1.5),
col=c("white", "gray"), main=myMthd)
axis(1, 1:nrow(whichAll[[myMthd]]), rownames(whichAll[[myMthd]]))
axis(2, 1:ncol(whichAll[[myMthd]]), colnames(whichAll[[myMthd]]), las=2)
}
par(old.par)
predict.regsubsets <- function (object, newdata, id, ...) {
form=as.formula(object$call [[2]])
mat=model.matrix(form, newdata)
coefi=coef(object, id=id)
xvars=names (coefi)
mat[, xvars] %*% coefi
}
dfTmp <- NULL
myDimnames <- list(NULL, colnames(model.matrix(contrib~.,fundRaisingData)), c("exhaustive", "backward", "forward", "seqrep"))
whichSum2 <- array(0, dim=c(15,15,4), dimnames = myDimnames)
# Split data into training and test 30 times:
nTries <- 30
for ( iTry in 1:nTries ) {
bTrain <- sample(rep(c(TRUE,FALSE),length.out=nrow(fundRaisingData)))
# Try each method available in regsubsets
# to select the best model of each size:
for ( jSelect in c("exhaustive", "backward", "forward", "seqrep") ) {
rsTrain2 <- regsubsets(contrib~.,fundRaisingData[bTrain,],nvmax=15,method=jSelect)
# Add up variable selections:
whichSum2[,,jSelect][1:14,] <- whichSum2[,,jSelect][1:14,] + summary(rsTrain2)$which
# Calculate test error for each set of variables
# using predict.regsubsets implemented above:
for ( kVarSet in 1:14 ) {
# make predictions:
testPred <- predict(rsTrain2,fundRaisingData[!bTrain,],id=kVarSet)
# calculate MSE:
mseTest <- mean((testPred-fundRaisingData[!bTrain,"contrib"])^2)
# add to data.frame for future plotting:
dfTmp <- rbind(dfTmp,data.frame(sim=iTry, sel=jSelect, vars=kVarSet,
mse=c(mseTest, summary(rsTrain2)$rss[kVarSet] / sum(bTrain)), trainTest=c("test","train")))
}
}
}
# plot MSEs by training/test, number of
# variables and selection method:
ggplot(dfTmp,aes(x=factor(vars),y=mse,colour=sel)) + geom_boxplot()+facet_wrap(~trainTest)+theme_bw()
# -1 to get rid of intercept that glmnet knows to include:
x <- model.matrix(contrib~.,fundRaisingData)[,-1]
head(fundRaisingData)
# notice how it created dummy variables for categorical attributes
head(x)
y <- fundRaisingData[,"contrib"]
ridgeRes <- glmnet(x,y,alpha=0)
plot(ridgeRes)
cvRidgeRes <- cv.glmnet(x,y,alpha=0)
plot(cvRidgeRes)
cvRidgeRes$lambda.min
cvRidgeRes$lambda.1se
predict(ridgeRes,type="coefficients",s=cvRidgeRes$lambda.min)
predict(ridgeRes,type="coefficients",s=cvRidgeRes$lambda.1se)
# and with lambda's other than default:
cvRidgeRes <- cv.glmnet(x,y,alpha=0,lambda=10^((-80:80)/20))
plot(cvRidgeRes)
ridgeResScaled <- glmnet(scale(x),y,alpha=0)
plot(ridgeResScaled)
cvRidgeResScaled <- cv.glmnet(scale(x),y,alpha=0)
plot(cvRidgeResScaled)
predict(ridgeResScaled,type="coefficients",s=cvRidgeResScaled$lambda.1se)
lassoRes <- glmnet(x,y,alpha=1)
plot(lassoRes)
cvLassoRes <- cv.glmnet(x,y,alpha=1)
plot(cvLassoRes)
# With other than default levels of lambda:
cvLassoRes <- cv.glmnet(x,y,alpha=1,lambda=10^((-120:0)/20))
plot(cvLassoRes)
predict(lassoRes,type="coefficients",s=cvLassoRes$lambda.1se)
predict(lassoRes,type="coefficients",s=cvLassoRes$lambda.min)
lassoResScaled <- glmnet(scale(x),y,alpha=1)
plot(lassoResScaled)
cvLassoResScaled <- cv.glmnet(scale(x),y,alpha=1)
plot(cvLassoResScaled)
predict(lassoResScaled,type="coefficients",s=cvLassoResScaled$lambda.1se)
lassoCoefCnt <- 0
lassoMSE <- NULL
for ( iTry in 1:30 ) {
bTrain <- sample(rep(c(TRUE,FALSE),length.out=nrow(x)))
cvLassoTrain <- cv.glmnet(x[bTrain,],y[bTrain],alpha=1)
lassoTrain <- glmnet(x[bTrain,],y[bTrain],alpha=1)
lassoTrainCoef <- predict(lassoTrain,type="coefficients",s=cvLassoTrain$lambda.1se)
lassoCoefCnt <- lassoCoefCnt + (lassoTrainCoef[-1,1]!=0)
lassoTestPred <- predict(lassoTrain,newx=x[!bTrain,],s=cvLassoTrain$lambda.1se)
lassoMSE <- c(lassoMSE,mean((lassoTestPred-y[!bTrain])^2))
}
mean(lassoMSE)
lassoCoefCnt
fundRaisingData <- read.table("fund-raising-with-predictions.csv", sep=",", header=TRUE)
# DON'T SKIP log-transform selected attributes:
# fundRaisingData[,1:8] <- log(fundRaisingData[,1:8])
# frd <- fundRaisingData
# fundRaisingData <- do.call(data.frame, lapply(frd, function(x) replace(x, is.infinite(x),NA)))
# FIXME: Doesn't work on Mac OS
# resize.win <- function(Width=6, Height=6) {
#         # works for windows
#     dev.off(); # dev.new(width=6, height=6)
#     windows(record=TRUE, width=Width, height=Height)
# }
# resize.win(1000,1000);
# pdf(file = "Rplot.pdf")
# pairs(fundRaisingData)
# dev.off()
summaryMetrics <- NULL
whichAll <- list()
for ( myMthd in c("exhaustive", "backward", "forward", "seqrep") ) {
# 15 because three categorical attributes are represented by dummy variables:
rsRes <- regsubsets(contrib~., fundRaisingData[, 1:12], method=myMthd, nvmax=12)
summRes <- summary(rsRes)
whichAll[[myMthd]] <- summRes$which
for ( metricName in c("rsq", "rss", "adjr2", "cp", "bic") ) {
summaryMetrics <- rbind(summaryMetrics,
data.frame(method=myMthd, metric=metricName,
nvars=1:length(summRes[[metricName]]),
value=summRes[[metricName]]))
}
}
ggplot(summaryMetrics, aes(x=nvars, y=value, shape=method, colour=method)) + geom_path() + geom_point() + facet_wrap(~metric, scales="free") +   theme(legend.position="top")+theme_bw()
old.par <- par(mfrow=c(2, 2), ps=16, mar=c(5, 7, 2, 1))
for ( myMthd in names(whichAll) ) {
image(1:nrow(whichAll[[myMthd]]),
1:ncol(whichAll[[myMthd]]),
whichAll[[myMthd]], xlab="N(vars)", ylab="",
xaxt="n", yaxt="n", breaks=c(-0.5, 0.5, 1.5),
col=c("white", "gray"), main=myMthd)
axis(1, 1:nrow(whichAll[[myMthd]]), rownames(whichAll[[myMthd]]))
axis(2, 1:ncol(whichAll[[myMthd]]), colnames(whichAll[[myMthd]]), las=2)
}
par(old.par)
predict.regsubsets <- function (object, newdata, id, ...) {
form=as.formula(object$call [[2]])
mat=model.matrix(form, newdata)
coefi=coef(object, id=id)
xvars=names (coefi)
mat[, xvars] %*% coefi
}
dfTmp <- NULL
myDimnames <- list(NULL, colnames(model.matrix(contrib~.,fundRaisingData)), c("exhaustive", "backward", "forward", "seqrep"))
whichSum2 <- array(0, dim=c(15,15,4), dimnames = myDimnames)
# Split data into training and test 30 times:
nTries <- 30
for ( iTry in 1:nTries ) {
bTrain <- sample(rep(c(TRUE,FALSE),length.out=nrow(fundRaisingData)))
# Try each method available in regsubsets
# to select the best model of each size:
for ( jSelect in c("exhaustive", "backward", "forward", "seqrep") ) {
rsTrain2 <- regsubsets(contrib~.,fundRaisingData[bTrain,],nvmax=15,method=jSelect)
# Add up variable selections:
whichSum2[,,jSelect][1:12,] <- whichSum2[,,jSelect][1:12,] + summary(rsTrain2)$which
# Calculate test error for each set of variables
# using predict.regsubsets implemented above:
for ( kVarSet in 1:12 ) {
# make predictions:
testPred <- predict(rsTrain2,fundRaisingData[!bTrain,],id=kVarSet)
# calculate MSE:
mseTest <- mean((testPred-fundRaisingData[!bTrain,"contrib"])^2)
# add to data.frame for future plotting:
dfTmp <- rbind(dfTmp,data.frame(sim=iTry, sel=jSelect, vars=kVarSet,
mse=c(mseTest, summary(rsTrain2)$rss[kVarSet] / sum(bTrain)), trainTest=c("test","train")))
}
}
}
whichSum2[,,jSelect][1:12,] + summary(rsTrain2)$which
whichSum2[,,jSelect][1:12,] + summary(rsTrain2)$which
head(summary(rsTrain2)$which)
head(whichSum2[,,jSelect][1:12,])
whichSum2[,,jSelect][1:12,]
(summary(rsTrain2)$which)
whichSum2[,,jSelect][1:12,]
(summary(rsTrain2)$which)
dfTmp <- NULL
myDimnames <- list(NULL, colnames(model.matrix(contrib~.,fundRaisingData)), c("exhaustive", "backward", "forward", "seqrep"))
whichSum2 <- array(0, dim=c(15,15,4), dimnames = myDimnames)
# Split data into training and test 30 times:
nTries <- 30
for ( iTry in 1:nTries ) {
bTrain <- sample(rep(c(TRUE,FALSE),length.out=nrow(fundRaisingData)))
# Try each method available in regsubsets
# to select the best model of each size:
for ( jSelect in c("exhaustive", "backward", "forward", "seqrep") ) {
rsTrain2 <- regsubsets(contrib~.,fundRaisingData[bTrain,],nvmax=15,method=jSelect)
# Add up variable selections:
whichSum2[,,jSelect][1:14,] <- whichSum2[,,jSelect][1:14,] + summary(rsTrain2)$which
# Calculate test error for each set of variables
# using predict.regsubsets implemented above:
for ( kVarSet in 1:12 ) {
# make predictions:
testPred <- predict(rsTrain2,fundRaisingData[!bTrain,],id=kVarSet)
# calculate MSE:
mseTest <- mean((testPred-fundRaisingData[!bTrain,"contrib"])^2)
# add to data.frame for future plotting:
dfTmp <- rbind(dfTmp,data.frame(sim=iTry, sel=jSelect, vars=kVarSet,
mse=c(mseTest, summary(rsTrain2)$rss[kVarSet] / sum(bTrain)), trainTest=c("test","train")))
}
}
}
# plot MSEs by training/test, number of
# variables and selection method:
ggplot(dfTmp,aes(x=factor(vars),y=mse,colour=sel)) + geom_boxplot()+facet_wrap(~trainTest)+theme_bw()
# -1 to get rid of intercept that glmnet knows to include:
x <- model.matrix(contrib~.,fundRaisingData)[,2:12]
head(fundRaisingData[,2:12])
# notice how it created dummy variables for categorical attributes
head(x)
y <- fundRaisingData[,2:12][,"contrib"]
# -1 to get rid of intercept that glmnet knows to include:
x <- model.matrix(contrib~.,fundRaisingData)[,2:12]
head(fundRaisingData[,2:12])
# notice how it created dummy variables for categorical attributes
head(x)
y <- fundRaisingData[,1:12][,"contrib"]
ridgeRes <- glmnet(x,y,alpha=0)
plot(ridgeRes)
cvRidgeRes <- cv.glmnet(x,y,alpha=0)
plot(cvRidgeRes)
cvRidgeRes$lambda.min
cvRidgeRes$lambda.1se
predict(ridgeRes,type="coefficients",s=cvRidgeRes$lambda.min)
predict(ridgeRes,type="coefficients",s=cvRidgeRes$lambda.1se)
# and with lambda's other than default:
cvRidgeRes <- cv.glmnet(x,y,alpha=0,lambda=10^((-80:80)/20))
plot(cvRidgeRes)
ridgeResScaled <- glmnet(scale(x),y,alpha=0)
plot(ridgeResScaled)
cvRidgeResScaled <- cv.glmnet(scale(x),y,alpha=0)
plot(cvRidgeResScaled)
predict(ridgeResScaled,type="coefficients",s=cvRidgeResScaled$lambda.1se)
lassoRes <- glmnet(x,y,alpha=1)
plot(lassoRes)
cvLassoRes <- cv.glmnet(x,y,alpha=1)
plot(cvLassoRes)
# With other than default levels of lambda:
cvLassoRes <- cv.glmnet(x,y,alpha=1,lambda=10^((-120:0)/20))
plot(cvLassoRes)
predict(lassoRes,type="coefficients",s=cvLassoRes$lambda.1se)
predict(lassoRes,type="coefficients",s=cvLassoRes$lambda.min)
lassoResScaled <- glmnet(scale(x),y,alpha=1)
plot(lassoResScaled)
cvLassoResScaled <- cv.glmnet(scale(x),y,alpha=1)
plot(cvLassoResScaled)
predict(lassoResScaled,type="coefficients",s=cvLassoResScaled$lambda.1se)
lassoCoefCnt <- 0
lassoMSE <- NULL
for ( iTry in 1:30 ) {
bTrain <- sample(rep(c(TRUE,FALSE),length.out=nrow(x)))
cvLassoTrain <- cv.glmnet(x[bTrain,],y[bTrain],alpha=1)
lassoTrain <- glmnet(x[bTrain,],y[bTrain],alpha=1)
lassoTrainCoef <- predict(lassoTrain,type="coefficients",s=cvLassoTrain$lambda.1se)
lassoCoefCnt <- lassoCoefCnt + (lassoTrainCoef[-1,1]!=0)
lassoTestPred <- predict(lassoTrain,newx=x[!bTrain,],s=cvLassoTrain$lambda.1se)
lassoMSE <- c(lassoMSE,mean((lassoTestPred-y[!bTrain])^2))
}
mean(lassoMSE)
lassoCoefCnt
?ggplot
dfTmp <- NULL
myDimnames <- list(NULL, colnames(model.matrix(contrib~.,fundRaisingData)), c("exhaustive", "backward", "forward", "seqrep"))
whichSum2 <- array(0, dim=c(15,15,4), dimnames = myDimnames)
# Split data into training and test 30 times:
nTries <- 30
for ( iTry in 1:nTries ) {
bTrain <- sample(rep(c(TRUE,FALSE),length.out=nrow(fundRaisingData)))
# Try each method available in regsubsets
# to select the best model of each size:
for ( jSelect in c("exhaustive", "backward", "forward", "seqrep") ) {
rsTrain2 <- regsubsets(contrib~.,fundRaisingData[bTrain,],nvmax=15,method=jSelect)
# Add up variable selections:
whichSum2[,,jSelect][1:14,] <- whichSum2[,,jSelect][1:14,] + summary(rsTrain2)$which
# Calculate test error for each set of variables
# using predict.regsubsets implemented above:
for ( kVarSet in 1:12 ) {
# make predictions:
testPred <- predict(rsTrain2,fundRaisingData[!bTrain,],id=kVarSet)
# calculate MSE:
mseTest <- mean((testPred-fundRaisingData[!bTrain,"contrib"])^2)
# add to data.frame for future plotting:
dfTmp <- rbind(dfTmp,data.frame(sim=iTry, sel=jSelect, vars=kVarSet,
mse=c(mseTest, summary(rsTrain2)$rss[kVarSet] / sum(bTrain)), trainTest=c("test","train")))
}
}
}
# plot MSEs by training/test, number of
# variables and selection method:
ggplot(dfTmp,aes(x=factor(vars),y=mse,colour=sel, ymax = 100)) + geom_boxplot() + facet_wrap(~trainTest) + theme_bw()
dfTmp <- NULL
myDimnames <- list(NULL, colnames(model.matrix(contrib~.,fundRaisingData)), c("exhaustive", "backward", "forward", "seqrep"))
whichSum2 <- array(0, dim=c(15,15,4), dimnames = myDimnames)
# Split data into training and test 30 times:
nTries <- 30
for ( iTry in 1:nTries ) {
bTrain <- sample(rep(c(TRUE,FALSE),length.out=nrow(fundRaisingData)))
# Try each method available in regsubsets
# to select the best model of each size:
for ( jSelect in c("exhaustive", "backward", "forward", "seqrep") ) {
rsTrain2 <- regsubsets(contrib~.,fundRaisingData[bTrain,],nvmax=15,method=jSelect)
# Add up variable selections:
whichSum2[,,jSelect][1:14,] <- whichSum2[,,jSelect][1:14,] + summary(rsTrain2)$which
# Calculate test error for each set of variables
# using predict.regsubsets implemented above:
for ( kVarSet in 1:12 ) {
# make predictions:
testPred <- predict(rsTrain2,fundRaisingData[!bTrain,],id=kVarSet)
# calculate MSE:
mseTest <- mean((testPred-fundRaisingData[!bTrain,"contrib"])^2)
# add to data.frame for future plotting:
dfTmp <- rbind(dfTmp,data.frame(sim=iTry, sel=jSelect, vars=kVarSet,
mse=c(mseTest, summary(rsTrain2)$rss[kVarSet] / sum(bTrain)), trainTest=c("test","train")))
}
}
}
# plot MSEs by training/test, number of
# variables and selection method:
ggplot(dfTmp,aes(x=factor(vars),y=mse,colour=sel)) + geom_boxplot() + scale_y_log10(breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x))) + facet_wrap(~trainTest) + theme_bw()
library(ISLR)
library(leaps)
library(ggplot2)
library(glmnet)
library(scales)
knitr::opts_chunk$set(echo = TRUE)
dfTmp <- NULL
myDimnames <- list(NULL, colnames(model.matrix(contrib~.,fundRaisingData)), c("exhaustive", "backward", "forward", "seqrep"))
whichSum2 <- array(0, dim=c(15,15,4), dimnames = myDimnames)
# Split data into training and test 30 times:
nTries <- 30
for ( iTry in 1:nTries ) {
bTrain <- sample(rep(c(TRUE,FALSE),length.out=nrow(fundRaisingData)))
# Try each method available in regsubsets
# to select the best model of each size:
for ( jSelect in c("exhaustive", "backward", "forward", "seqrep") ) {
rsTrain2 <- regsubsets(contrib~.,fundRaisingData[bTrain,],nvmax=15,method=jSelect)
# Add up variable selections:
whichSum2[,,jSelect][1:14,] <- whichSum2[,,jSelect][1:14,] + summary(rsTrain2)$which
# Calculate test error for each set of variables
# using predict.regsubsets implemented above:
for ( kVarSet in 1:12 ) {
# make predictions:
testPred <- predict(rsTrain2,fundRaisingData[!bTrain,],id=kVarSet)
# calculate MSE:
mseTest <- mean((testPred-fundRaisingData[!bTrain,"contrib"])^2)
# add to data.frame for future plotting:
dfTmp <- rbind(dfTmp,data.frame(sim=iTry, sel=jSelect, vars=kVarSet,
mse=c(mseTest, summary(rsTrain2)$rss[kVarSet] / sum(bTrain)), trainTest=c("test","train")))
}
}
}
# plot MSEs by training/test, number of
# variables and selection method:
ggplot(dfTmp,aes(x=factor(vars),y=mse,colour=sel)) + geom_boxplot() + scale_y_log10(breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x))) + facet_wrap(~trainTest) + theme_bw()
mse(sim, obs, ...)
head(fundRaisingData)
mse(fundRaisingData[, "contrib""], fundRaisingData[, "predcontr])
mse(fundRaisingData[, "contrib""], fundRaisingData[, "predcontr""])
mse(fundRaisingData[, "contrib""], fundRaisingData[, "predcontr"])
mse(fundRaisingData[, "contrib], fundRaisingData[, "predcontr"])
mse(fundRaisingData[, "contrib"], fundRaisingData[, "predcontr"])
?rmse
?mse
library(hydroGOF)
library("hydroGOF")
library(hydroGOF)
?I
?poly
?exp
install.packages("readxl")
library(readxl)
read_excel("Real estate valuation data set.xlsx")
?read_excel
library(readxl)
read_estate_data <- read_excel("Real estate valuation data set.xlsx")
library(readxl)
real_estate_data <- read_excel("Real estate valuation data set.xlsx")
pairs(real_estate_data)
library(readxl)
real_estate_data <- read_excel("Real estate valuation data set.xlsx")
par(mfrow=c(8,8))
pairs(real_estate_data)
?par
library(readxl)
real_estate_data <- read_excel("Real estate valuation data set.xlsx")
par(mfrow=c(8,8), fin=c(1000,1000))
pairs(real_estate_data)
library(readxl)
real_estate_data <- read_excel("Real estate valuation data set.xlsx")
par(mfrow=c(8,8), fin=c(1000,1000))
pdf("my_plot.pdf", width=6, height=4)
pairs(real_estate_data)
dev.off()
library(readxl)
real_estate_data <- read_excel("Real estate valuation data set.xlsx")
par(mfrow=c(8,8), fin=c(1000,1000))
pdf("my_plot.pdf", width=16, height=14)
pairs(real_estate_data)
dev.off()
